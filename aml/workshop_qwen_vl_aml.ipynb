{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4f6649",
   "metadata": {},
   "source": [
    "# 1. Azure ML å‰ç½®å‡†å¤‡\n",
    "\n",
    "æœ¬ç« èŠ‚æ¶µç›– Azure ML å·¥ä½œåŒºçš„åˆ›å»ºä¸è¿æ¥ã€æœ¬åœ°ç¯å¢ƒé…ç½®ç­‰å‰ç½®å‡†å¤‡å·¥ä½œã€‚\n",
    "\n",
    "- **1.1** å®‰è£…æœ¬åœ°ä¾èµ–\n",
    "- **1.2** åˆ›å»º Azure ML å·¥ä½œåŒº(å¦‚å·²æœ‰å·¥ä½œåŒºå¯è·³è¿‡)\n",
    "- **1.3** è¿æ¥ Azure ML å·¥ä½œåŒº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22b523",
   "metadata": {},
   "source": [
    "# ç«¯åˆ°ç«¯ï¼šAzure VM å‡†å¤‡ + Azure ML ä¸Šä½¿ç”¨ LoRA å¾®è°ƒ Qwen3-VL-4B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03860939",
   "metadata": {},
   "source": [
    "## 1.1 å®‰è£…æœ¬åœ°ä¾èµ–(ä»… Notebook è¿è¡Œç¯å¢ƒ)\n",
    "\n",
    "- æœ¬èŠ‚ä¸ºä½ çš„æœ¬æœº/Notebook å†…æ ¸å®‰è£…æœ€å°ä¾èµ–,ä¾¿äºè¿æ¥ Azure MLã€åšæ•°æ®é¢„å¤„ç†ä¸å¯è§†åŒ–ã€‚\n",
    "- è®­ç»ƒå°†åœ¨ Azure ML è®¡ç®—ä¸Šæ‰§è¡Œ,æœ¬æœºä¸å®‰è£… torch/transformers ç­‰å¤§ä¾èµ–ã€‚\n",
    "- è‹¥ä½ åœ¨ä¸­å›½ä¸»æƒäº‘(è®¾ç½® AZURE_CLOUD_NAME=AzureChinaCloud),å®‰è£…å‘½ä»¤ä¼šè‡ªåŠ¨åˆ‡æ¢é•œåƒæºã€‚\n",
    "- å¦‚å·²æœ‰æ»¡è¶³æ¡ä»¶çš„ç¯å¢ƒ,å¯è·³è¿‡æœ¬èŠ‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4287f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements-notebook.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements-notebook.txt\n",
    "# æœ€å°ä¾èµ–ï¼ˆNotebook ç«¯ï¼‰\n",
    "# è®­ç»ƒå‘ç”Ÿåœ¨ Azure ML è®¡ç®—ä¸Šï¼Œæœ¬åœ°æ— éœ€å®‰è£… torch/transformers ç­‰å¤§ä¾èµ–\n",
    "azure-ai-ml>=1.15.0\n",
    "azure-identity>=1.16.0\n",
    "pandas>=2.1.0\n",
    "pyarrow>=15.0.0\n",
    "pillow>=10.2.0\n",
    "tqdm>=4.66.0\n",
    "ipywidgets>=8.1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafac309",
   "metadata": {},
   "source": [
    "## 1.3 è¿æ¥ Azure ML å·¥ä½œåŒº\n",
    "\n",
    "å®Œæˆå·¥ä½œåŒºåˆ›å»º(æˆ–ä½¿ç”¨å·²æœ‰å·¥ä½œåŒº)å,åœ¨æœ¬åœ° Notebook ç¯å¢ƒä¸­é€šè¿‡ Python SDK è¿æ¥åˆ° Azure ML å·¥ä½œåŒºã€‚\n",
    "\n",
    "ä»¥ä¸‹ç¤ºä¾‹ä»£ç å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `InteractiveBrowserCredential` è¿›è¡Œèº«ä»½éªŒè¯å¹¶åˆ›å»º `MLClient` å¯¹è±¡:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fvvhpkgm5bc",
   "metadata": {},
   "source": [
    "## 1.2 åˆ›å»º Azure Machine Learning å·¥ä½œåŒº\n",
    "\n",
    "æœ¬èŠ‚å°†æŒ‡å¯¼ä½ åœ¨ Azure é—¨æˆ·ä¸Šåˆ›å»º Azure Machine Learning å·¥ä½œåŒº,è¿™æ˜¯è¿è¡Œ Azure ML è®­ç»ƒä½œä¸šçš„å‰ç½®æ¡ä»¶ã€‚\n",
    "\n",
    "**å¦‚æœä½ å·²æœ‰å·¥ä½œåŒº,å¯è·³è¿‡æœ¬èŠ‚,ç›´æ¥è¿›å…¥ 1.3 è¿æ¥å·¥ä½œåŒºã€‚**\n",
    "\n",
    "### 1.2.1 å‰ç½®æ¡ä»¶\n",
    "- Azure è®¢é˜…å…·å¤‡åˆ›å»º Azure ML å·¥ä½œåŒºçš„æƒé™ã€‚\n",
    "- æœ¬åœ°å·²å®‰è£… Azure CLI æˆ–èƒ½å¤Ÿç™»å½• Azure é—¨æˆ·ã€‚\n",
    "- å·²è§„åˆ’å¥½èµ„æºç»„åç§°å’Œå·¥ä½œåŒºæ‰€åœ¨åŒºåŸŸã€‚\n",
    "\n",
    "### 1.2.2 ç™»å½• Azure é—¨æˆ·\n",
    "\n",
    "æ ¹æ®ä½ çš„äº‘ç¯å¢ƒé€‰æ‹©å¯¹åº”çš„é—¨æˆ·:\n",
    "- **å…¬æœ‰äº‘**: [https://portal.azure.com/](https://portal.azure.com/)\n",
    "- **ä¸­å›½åŒº**: [https://portal.azure.cn/](https://portal.azure.cn/)\n",
    "\n",
    "ä½¿ç”¨ä½ çš„ Azure è´¦å·ç™»å½•ã€‚\n",
    "\n",
    "### 1.2.3 åˆ›å»º Azure Machine Learning å·¥ä½œåŒº\n",
    "\n",
    "#### è¿›å…¥åˆ›å»ºå‘å¯¼\n",
    "1. åœ¨ Azure é—¨æˆ·ä¸»é¡µ,ç‚¹å‡»å·¦ä¸Šè§’çš„ **\"åˆ›å»ºèµ„æº\"** æŒ‰é’®ã€‚\n",
    "   - ![åˆ›å»ºèµ„æºå…¥å£](images/azure_ml_create_resource.png)\n",
    "2. åœ¨æœç´¢æ¡†ä¸­è¾“å…¥ **\"Machine Learning\"**,é€‰æ‹© **\"Azure Machine Learning\"**ã€‚\n",
    "   - ![æœç´¢ ML æœåŠ¡](images/azure_ml_search.png)\n",
    "3. ç‚¹å‡» **\"åˆ›å»º\"** æŒ‰é’®,è¿›å…¥å·¥ä½œåŒºåˆ›å»ºå‘å¯¼ã€‚\n",
    "   - ![å¼€å§‹åˆ›å»º](images/azure_ml_create_start.png)\n",
    "\n",
    "#### åŸºæœ¬ä¿¡æ¯é…ç½®\n",
    "åœ¨ **\"åŸºæœ¬ä¿¡æ¯\"** é¡µç­¾å¡«å†™ä»¥ä¸‹å†…å®¹:\n",
    "\n",
    "| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹å€¼ |\n",
    "|------|------|--------|\n",
    "| **è®¢é˜…** | é€‰æ‹©ä½ çš„ Azure è®¢é˜… | `Pay-As-You-Go` |\n",
    "| **èµ„æºç»„** | é€‰æ‹©ç°æœ‰èµ„æºç»„æˆ–åˆ›å»ºæ–°èµ„æºç»„ | `OctWorkRG` |\n",
    "| **å·¥ä½œåŒºåç§°** | å·¥ä½œåŒºçš„å”¯ä¸€åç§°(3-33å­—ç¬¦,å­—æ¯æ•°å­—å’Œè¿å­—ç¬¦) | `ml-cn3-01` |\n",
    "| **åŒºåŸŸ** | é€‰æ‹©å·¥ä½œåŒºéƒ¨ç½²çš„ Azure åŒºåŸŸ | `chinanorth3` æˆ– `eastus` |\n",
    "| **å­˜å‚¨è´¦æˆ·** | é»˜è®¤æ–°å»º,æˆ–é€‰æ‹©ç°æœ‰å­˜å‚¨è´¦æˆ· | é»˜è®¤è‡ªåŠ¨åˆ›å»º |\n",
    "| **Key Vault** | é»˜è®¤æ–°å»º,ç”¨äºå­˜å‚¨å¯†é’¥å’Œå‡­æ® | é»˜è®¤è‡ªåŠ¨åˆ›å»º |\n",
    "| **Application Insights** | é»˜è®¤æ–°å»º,ç”¨äºç›‘æ§å’Œæ—¥å¿— | é»˜è®¤è‡ªåŠ¨åˆ›å»º |\n",
    "| **å®¹å™¨æ³¨å†Œè¡¨** | å¯é€‰,ç”¨äºå­˜å‚¨ Docker é•œåƒ | é¦–æ¬¡å¯ç•™ç©º |\n",
    "\n",
    "![åŸºæœ¬ä¿¡æ¯é…ç½®](images/azure_ml_basics.png)\n",
    "\n",
    "**é‡è¦æç¤º**:\n",
    "- **åŒºåŸŸé€‰æ‹©**: ç¡®ä¿é€‰æ‹©çš„åŒºåŸŸæ”¯æŒä½ åç»­éœ€è¦çš„ GPU VM SKU(å¦‚ NVads A10 v5)ã€‚\n",
    "- **èµ„æºç»„**: å»ºè®®å°†ç›¸å…³èµ„æºæ”¾åœ¨åŒä¸€èµ„æºç»„,ä¾¿äºç®¡ç†å’Œæˆæœ¬è·Ÿè¸ªã€‚\n",
    "\n",
    "#### ç½‘ç»œé…ç½®(å¯é€‰)\n",
    "åœ¨ **\"ç½‘ç»œ\"** é¡µç­¾å¯ä»¥é…ç½®å·¥ä½œåŒºçš„ç½‘ç»œè®¿é—®æ–¹å¼:\n",
    "- **å…¬å…±ç»ˆç»“ç‚¹(æ‰€æœ‰ç½‘ç»œ)**: é»˜è®¤é€‰é¡¹,å…è®¸ä»ä»»ä½•ä½ç½®è®¿é—®ã€‚\n",
    "- **ä¸“ç”¨ç»ˆç»“ç‚¹**: é€šè¿‡è™šæ‹Ÿç½‘ç»œç§å¯†è®¿é—®,é€‚åˆä¼ä¸šå®‰å…¨è¦æ±‚ã€‚\n",
    "\n",
    "å¯¹äºå¼€å‘å’Œå­¦ä¹ åœºæ™¯,ä½¿ç”¨é»˜è®¤çš„ **\"å…¬å…±ç»ˆç»“ç‚¹(æ‰€æœ‰ç½‘ç»œ)\"** å³å¯ã€‚\n",
    "\n",
    "![ç½‘ç»œé…ç½®](images/azure_ml_network.png)\n",
    "\n",
    "#### é«˜çº§é…ç½®(å¯é€‰)\n",
    "åœ¨ **\"é«˜çº§\"** é¡µç­¾å¯ä»¥é…ç½®:\n",
    "- **æ•°æ®åŠ å¯†**: é€‰æ‹©ä½¿ç”¨ Microsoft æ‰˜ç®¡å¯†é’¥è¿˜æ˜¯å®¢æˆ·æ‰˜ç®¡å¯†é’¥ã€‚\n",
    "- **æ ‡è¯†**: é…ç½®ç³»ç»Ÿåˆ†é…æˆ–ç”¨æˆ·åˆ†é…çš„æ‰˜ç®¡æ ‡è¯†ã€‚\n",
    "- **æ ‡ç­¾**: ä¸ºèµ„æºæ·»åŠ æ ‡ç­¾,ä¾¿äºåˆ†ç±»å’Œè®¡è´¹è·Ÿè¸ªã€‚\n",
    "\n",
    "å¯¹äºåˆæ¬¡ä½¿ç”¨,ä½¿ç”¨é»˜è®¤é…ç½®å³å¯ã€‚\n",
    "\n",
    "![é«˜çº§é…ç½®](images/azure_ml_advanced.png)\n",
    "\n",
    "#### æ£€æŸ¥å¹¶åˆ›å»º\n",
    "1. ç‚¹å‡» **\"æ£€æŸ¥ + åˆ›å»º\"** æŒ‰é’®ã€‚\n",
    "   - ![æ£€æŸ¥é…ç½®](images/azure_ml_review.png)\n",
    "2. Azure ä¼šéªŒè¯ä½ çš„é…ç½®,ç¡®è®¤æ‰€æœ‰å­—æ®µéƒ½æ­£ç¡®å¡«å†™ä¸”ç¬¦åˆè§„åˆ™ã€‚\n",
    "3. æ£€æŸ¥é…ç½®æ‘˜è¦,ç¡®è®¤æ— è¯¯åç‚¹å‡» **\"åˆ›å»º\"** æŒ‰é’®ã€‚\n",
    "   - ![ç¡®è®¤åˆ›å»º](images/azure_ml_create_confirm.png)\n",
    "4. éƒ¨ç½²è¿‡ç¨‹é€šå¸¸éœ€è¦ **2-5 åˆ†é’Ÿ**,å¯ä»¥åœ¨é€šçŸ¥é¢æ¿æŸ¥çœ‹è¿›åº¦ã€‚\n",
    "   - ![éƒ¨ç½²è¿›è¡Œä¸­](images/azure_ml_deployment.png)\n",
    "\n",
    "### 1.2.4 éªŒè¯å·¥ä½œåŒºåˆ›å»ºæˆåŠŸ\n",
    "\n",
    "#### æŸ¥çœ‹éƒ¨ç½²ç»“æœ\n",
    "1. éƒ¨ç½²å®Œæˆå,ç‚¹å‡» **\"è½¬åˆ°èµ„æº\"** æŒ‰é’®ã€‚\n",
    "   - ![éƒ¨ç½²å®Œæˆ](images/azure_ml_deployment_complete.png)\n",
    "2. è¿›å…¥å·¥ä½œåŒºæ¦‚è§ˆé¡µé¢,ç¡®è®¤ä»¥ä¸‹ä¿¡æ¯:\n",
    "   - å·¥ä½œåŒºåç§°ã€èµ„æºç»„ã€è®¢é˜… ID\n",
    "   - å·¥ä½œåŒº URL(ç”¨äºè®¿é—® Azure ML Studio)\n",
    "   - å…³è”çš„å­˜å‚¨è´¦æˆ·ã€Key Vault ç­‰èµ„æº\n",
    "\n",
    "![å·¥ä½œåŒºæ¦‚è§ˆ](images/azure_ml_workspace_overview.png)\n",
    "\n",
    "#### è®¿é—® Azure ML Studio\n",
    "1. åœ¨å·¥ä½œåŒºæ¦‚è§ˆé¡µç‚¹å‡» **\"å¯åŠ¨å·¥ä½œå®¤\"** æŒ‰é’®,æˆ–ç›´æ¥è®¿é—®:\n",
    "   - **å…¬æœ‰äº‘**: [https://ml.azure.com/](https://ml.azure.com/)\n",
    "   - **ä¸­å›½åŒº**: [https://ml.azure.cn/](https://ml.azure.cn/)\n",
    "2. é€‰æ‹©ä½ åˆ›å»ºçš„å·¥ä½œåŒº,è¿›å…¥ Azure ML Studio ç®¡ç†ç•Œé¢ã€‚\n",
    "   - ![ML Studio é¦–é¡µ](images/azure_ml_studio.png)\n",
    "\n",
    "### 1.2.5 åˆ›å»ºè®¡ç®—é›†ç¾¤(å¯é€‰,ä¹Ÿå¯é€šè¿‡ä»£ç åˆ›å»º)\n",
    "\n",
    "å¦‚æœä½ æƒ³é€šè¿‡é—¨æˆ·åˆ›å»ºè®¡ç®—é›†ç¾¤,å¯ä»¥æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œ:\n",
    "\n",
    "#### è¿›å…¥è®¡ç®—é¡µé¢\n",
    "1. åœ¨ Azure ML Studio å·¦ä¾§å¯¼èˆªæ ,ç‚¹å‡» **\"è®¡ç®—\"**ã€‚\n",
    "2. é€‰æ‹© **\"è®¡ç®—ç¾¤é›†\"** é€‰é¡¹å¡ã€‚\n",
    "3. ç‚¹å‡» **\"+ æ–°å»º\"** æŒ‰é’®ã€‚\n",
    "   - ![åˆ›å»ºè®¡ç®—é›†ç¾¤](images/azure_ml_aks_create.png)\n",
    "\n",
    "#### é…ç½®è®¡ç®—é›†ç¾¤\n",
    "å¡«å†™ä»¥ä¸‹é…ç½®:\n",
    "\n",
    "| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹å€¼ |\n",
    "|------|------|--------|\n",
    "| **è®¡ç®—åç§°** | é›†ç¾¤çš„å”¯ä¸€åç§° | `gpu-cluster` |\n",
    "| **è™šæ‹Ÿæœºå¤§å°** | é€‰æ‹© VM SKU(æ”¯æŒ GPU çš„èŠ‚ç‚¹) | `Standard_NVads_A10_v5` |\n",
    "| **æœ€å°èŠ‚ç‚¹æ•°** | æœ€å°èŠ‚ç‚¹æ•°é‡(0è¡¨ç¤ºç©ºé—²æ—¶è‡ªåŠ¨ç¼©å‡) | `0` |\n",
    "| **æœ€å¤§èŠ‚ç‚¹æ•°** | æœ€å¤§èŠ‚ç‚¹æ•°é‡ | `4` |\n",
    "| **ç©ºé—²æ—¶é—´** | èŠ‚ç‚¹ç©ºé—²å¤šä¹…åè‡ªåŠ¨ç¼©å‡ | `120` ç§’ |\n",
    "\n",
    "![é…ç½®è®¡ç®—é›†ç¾¤](images/azure_ml_aks_config.png)\n",
    "\n",
    "**é‡è¦æç¤º**:\n",
    "- **æˆæœ¬æ§åˆ¶**: è®¾ç½®æœ€å°èŠ‚ç‚¹æ•°ä¸º0,ç©ºé—²æ—¶è‡ªåŠ¨ç¼©å‡,é¿å…ä¸å¿…è¦çš„è´¹ç”¨ã€‚\n",
    "- **GPU æ”¯æŒ**: ç¡®ä¿é€‰æ‹©çš„ VM SKU æ”¯æŒ GPU(NCã€NV ç³»åˆ—)ã€‚\n",
    "\n",
    "#### å®Œæˆåˆ›å»º\n",
    "1. ç‚¹å‡» **\"åˆ›å»º\"** æŒ‰é’®ã€‚\n",
    "2. è®¡ç®—é›†ç¾¤åˆ›å»ºé€šå¸¸éœ€è¦ **5-10 åˆ†é’Ÿ**,å®ŒæˆåçŠ¶æ€å˜ä¸º **\"æˆåŠŸ\"**ã€‚\n",
    "\n",
    "![è®¡ç®—é›†ç¾¤åˆ—è¡¨](images/azure_ml_aks_list.png)\n",
    "\n",
    "### 1.2.6 è·å–å·¥ä½œåŒºè¿æ¥ä¿¡æ¯\n",
    "\n",
    "å®Œæˆå·¥ä½œåŒºåˆ›å»ºå,ä½ éœ€è¦ä»¥ä¸‹ä¿¡æ¯æ¥é€šè¿‡ Python SDK è¿æ¥å·¥ä½œåŒº:\n",
    "\n",
    "#### é€šè¿‡é—¨æˆ·è·å–\n",
    "åœ¨å·¥ä½œåŒºæ¦‚è§ˆé¡µé¢å¯ä»¥æ‰¾åˆ°:\n",
    "- **è®¢é˜… ID**: åœ¨ \"åŸºæœ¬ä¿¡æ¯\" éƒ¨åˆ†\n",
    "- **èµ„æºç»„**: åœ¨ \"åŸºæœ¬ä¿¡æ¯\" éƒ¨åˆ†\n",
    "- **å·¥ä½œåŒºåç§°**: é¡µé¢é¡¶éƒ¨æ ‡é¢˜\n",
    "\n",
    "![è·å–è¿æ¥ä¿¡æ¯](images/azure_ml_connection_info.png)\n",
    "\n",
    "#### é€šè¿‡ Azure CLI è·å–\n",
    "```bash\n",
    "# åˆ—å‡ºè®¢é˜…\n",
    "az account list --output table\n",
    "\n",
    "# åˆ—å‡ºèµ„æºç»„\n",
    "az group list --output table\n",
    "\n",
    "# åˆ—å‡ºå·¥ä½œåŒº\n",
    "az ml workspace list --resource-group <èµ„æºç»„åç§°> --output table\n",
    "\n",
    "# æ˜¾ç¤ºå·¥ä½œåŒºè¯¦æƒ…\n",
    "az ml workspace show --name <å·¥ä½œåŒºåç§°> --resource-group <èµ„æºç»„åç§°>\n",
    "```\n",
    "\n",
    "è®°å½•è¿™äº›ä¿¡æ¯,å°†åœ¨ä¸‹ä¸€èŠ‚ **1.3 è¿æ¥å·¥ä½œåŒº** ä¸­ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9531065",
   "metadata": {},
   "source": [
    "# 2. æ­£å¼æ“ä½œ\n",
    "\n",
    "å‰ç½®å‡†å¤‡å®Œæˆå,æœ¬ç« èŠ‚å°†å®Œæˆä»¥ä¸‹æ“ä½œ:\n",
    "- é€šè¿‡ Azure SDK äº¤äº’å¼ç™»å½•å¹¶è¿æ¥å·¥ä½œåŒº\n",
    "- å‡†å¤‡æ•°æ®é›†å¹¶æ³¨å†Œåˆ° Azure ML\n",
    "- åœ¨ Azure ML è®¡ç®—é›†ç¾¤ä¸Šè¿è¡Œ LLaMA-Factory è®­ç»ƒä½œä¸š\n",
    "- å¯¼å‡ºåˆå¹¶æ¨¡å‹å¹¶æ³¨å†Œä¸ºæ¨¡å‹èµ„äº§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i8uqv9qg3jr",
   "metadata": {},
   "source": [
    "## 2.1 äº¤äº’å¼ç™»å½•å¹¶è¿æ¥å·¥ä½œåŒº\n",
    "\n",
    "ä½¿ç”¨ Azure SDK è¿›è¡Œäº¤äº’å¼èº«ä»½éªŒè¯,å¹¶è¿æ¥åˆ°ä½ åœ¨ç¬¬ 1 ç« åˆ›å»ºæˆ–å‡†å¤‡å¥½çš„ Azure ML å·¥ä½œåŒºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09265db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace: aml-hu-east-west-us2\n",
      "Location: westus2\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import InteractiveBrowserCredential, AzureAuthorityHosts\n",
    "from azure.ai.ml import MLClient\n",
    "import os\n",
    "\n",
    "# åŸºç¡€é…ç½®ï¼ˆå¯ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰\n",
    "# SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\", \"3e859a28-17f7-420e-bc02-624301a676f7\")\n",
    "# RESOURCE_GROUP = os.getenv(\"AZURE_RESOURCE_GROUP\", \"OctWorkRG\")\n",
    "# WORKSPACE_NAME = os.getenv(\"AZUREML_WORKSPACE_NAME\", \"ml-cn3-01\")\n",
    "SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\", \"7a03e9b8-18d6-48e7-b186-0ec68da9e86f\")\n",
    "RESOURCE_GROUP = os.getenv(\"AZURE_RESOURCE_GROUP\", \"aml-rg\")\n",
    "WORKSPACE_NAME = os.getenv(\"AZUREML_WORKSPACE_NAME\", \"aml-hu-east-west-us2\")\n",
    "\n",
    "# åˆ‡æ¢å…¬æœ‰äº‘/ä¸»æƒäº‘ï¼ˆAzureChinaCloudï¼‰\n",
    "USE_CHINA_CLOUD = False\n",
    "authority_host = AzureAuthorityHosts.AZURE_CHINA if USE_CHINA_CLOUD else AzureAuthorityHosts.AZURE_PUBLIC_CLOUD\n",
    "ml_client_kwargs = {\"cloud\": \"AzureChinaCloud\"} if USE_CHINA_CLOUD else {}\n",
    "\n",
    "# äº¤äº’å¼ç™»å½•\n",
    "credential = InteractiveBrowserCredential(authority=authority_host,tenant_id=\"16b3c013-d300-468d-ac64-7eda0820b6d3\")\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    "    **ml_client_kwargs,\n",
    ")\n",
    "\n",
    "print(f\"Connected to workspace: {ml_client.workspace_name}\")\n",
    "workspace = ml_client.workspaces.get(ml_client.workspace_name)\n",
    "print(f\"Location: {workspace.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257022d",
   "metadata": {},
   "source": [
    "## 2.2 å‡†å¤‡ç›®å½•ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e791e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace_dir: /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl\n",
      "src_dir: /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/src\n",
      "datasets_dir: /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/datasets\n",
      "config_dir: /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/config\n",
      "outputs_dir: /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/outputs\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "workspace_dir = pathlib.Path.cwd() / \"workshop_qwen_vl\"\n",
    "src_dir = workspace_dir / \"src\"\n",
    "env_dir = workspace_dir / \"env\"\n",
    "datasets_dir = workspace_dir / \"datasets\"\n",
    "config_dir = workspace_dir / \"config\"\n",
    "outputs_dir = workspace_dir / \"outputs\"\n",
    "\n",
    "for d in [workspace_dir, src_dir, env_dir, datasets_dir, config_dir, outputs_dir]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"workspace_dir:\", workspace_dir)\n",
    "print(\"src_dir:\", src_dir)\n",
    "print(\"datasets_dir:\", datasets_dir)\n",
    "print(\"config_dir:\", config_dir)\n",
    "print(\"outputs_dir:\", outputs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f8dad",
   "metadata": {},
   "source": [
    "## 2.3 ä¸‹è½½å¹¶å¤„ç† vqav2-small æ•°æ®é›†ä¸º LLaMA-Factory JSON\n",
    "\n",
    "æ•°æ®é›†åœ°å€ï¼šhttps://huggingface.co/datasets/merve/vqav2-small\n",
    "\n",
    "ä»æœ¬åœ° parquet ç›®å½•è¯»å–æ ·æœ¬å­—èŠ‚å›¾åƒ,å¯¼å‡ºåˆ° `train_images/val_images`,å¹¶ç”Ÿæˆ `vqav2small_train.json` ä¸ `vqav2small_val.json`(messages/images ç»“æ„)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759ea8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯»å–æ‰€æœ‰ parquet æ–‡ä»¶...\n",
      "å…±åŠ è½½ 21435 æ¡æ ·æœ¬\n",
      "æ‹†åˆ†ç»“æœï¼šè®­ç»ƒé›† 900 æ¡ï¼ŒéªŒè¯é›† 100 æ¡\n",
      "å¼€å§‹å¯¼å‡º train é›†\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 900/900 [00:03<00:00, 299.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train é›†å¯¼å‡ºå®Œæˆï¼Œå…± 900 æ¡æ ·æœ¬ï¼Œå›¾ç‰‡ä¿å­˜åœ¨ /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/datasets/vqav2small/train_images\n",
      "å¼€å§‹å¯¼å‡º val é›†\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 469.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val é›†å¯¼å‡ºå®Œæˆï¼Œå…± 100 æ¡æ ·æœ¬ï¼Œå›¾ç‰‡ä¿å­˜åœ¨ /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/datasets/vqav2small/val_images\n",
      "å…¨éƒ¨æ•°æ®é›†å¯¼å‡ºå®Œæˆã€‚è¾“å‡ºç›®å½•ï¼š /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/datasets/vqav2small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# é…ç½®ï¼šè‹¥ä½ å·²å°† parquet ä¸‹è½½åˆ°æœ¬åœ°ç›®å½•ï¼Œä¿®æ”¹æ­¤è·¯å¾„\n",
    "parquet_dir = os.path.join(datasets_dir.as_posix(), \"merve--vqav2-small\")\n",
    "output_base_dir = os.path.join(datasets_dir.as_posix(), \"vqav2small\")\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "max_samples = 1000  # å¯æ”¹ä¸º None è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨\n",
    "val_ratio = 0.1\n",
    "\n",
    "splits = {\n",
    "    \"train\": {\n",
    "        \"img_dir\": os.path.join(output_base_dir, \"train_images\"),\n",
    "        \"json_path\": os.path.join(output_base_dir, \"vqav2small_train.json\"),\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"img_dir\": os.path.join(output_base_dir, \"val_images\"),\n",
    "        \"json_path\": os.path.join(output_base_dir, \"vqav2small_val.json\"),\n",
    "    },\n",
    "}\n",
    "for split in splits.values():\n",
    "    os.makedirs(split[\"img_dir\"], exist_ok=True)\n",
    "\n",
    "print(\"è¯»å–æ‰€æœ‰ parquet æ–‡ä»¶...\")\n",
    "all_rows = []\n",
    "for file in sorted(os.listdir(parquet_dir)):\n",
    "    if not file.endswith(\".parquet\"):\n",
    "        continue\n",
    "    df = pd.read_parquet(os.path.join(parquet_dir, file))\n",
    "    for idx, row in df.iterrows():\n",
    "        all_rows.append((file, idx, row))\n",
    "print(f\"å…±åŠ è½½ {len(all_rows)} æ¡æ ·æœ¬\")\n",
    "\n",
    "random.seed(42)\n",
    "if max_samples and len(all_rows) > max_samples:\n",
    "    all_rows = random.sample(all_rows, max_samples)\n",
    "\n",
    "random.shuffle(all_rows)\n",
    "split_index = int(len(all_rows) * (1 - val_ratio))\n",
    "train_rows = all_rows[:split_index]\n",
    "val_rows = all_rows[split_index:]\n",
    "print(f\"æ‹†åˆ†ç»“æœï¼šè®­ç»ƒé›† {len(train_rows)} æ¡ï¼ŒéªŒè¯é›† {len(val_rows)} æ¡\")\n",
    "\n",
    "def export_split(split_name, rows):\n",
    "    cfg = splits[split_name]\n",
    "    json_output = []\n",
    "    print(f\"å¼€å§‹å¯¼å‡º {split_name} é›†\")\n",
    "    for file, idx, row in tqdm(rows):\n",
    "        try:\n",
    "            img_bytes = row[\"image\"][\"bytes\"]\n",
    "            img = Image.open(BytesIO(img_bytes)).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"å›¾ç‰‡è§£ç å¤±è´¥: {file}_{idx}, é”™è¯¯: {e}\")\n",
    "            continue\n",
    "        img_name = f\"{split_name}_{file}_{idx}.jpg\"\n",
    "        img_path = os.path.join(cfg[\"img_dir\"], img_name)\n",
    "        img.save(img_path)\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"<image>{row['question']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"multiple_choice_answer\"]},\n",
    "        ]\n",
    "        json_output.append({\"messages\": messages, \"images\": [img_path]})\n",
    "    with open(cfg[\"json_path\"], \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_output, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"{split_name} é›†å¯¼å‡ºå®Œæˆï¼Œå…± {len(json_output)} æ¡æ ·æœ¬ï¼Œå›¾ç‰‡ä¿å­˜åœ¨ {cfg['img_dir']}\")\n",
    "\n",
    "export_split(\"train\", train_rows)\n",
    "export_split(\"val\", val_rows)\n",
    "print(\"å…¨éƒ¨æ•°æ®é›†å¯¼å‡ºå®Œæˆã€‚è¾“å‡ºç›®å½•ï¼š\", output_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23667ce",
   "metadata": {},
   "source": [
    "## 2.4 æ³¨å†Œ Azure ML æ•°æ®èµ„äº§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa543272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ly/p_d2t4qx1pn8t41fwvpnykx00000gp/T/ipykernel_53321/3604369608.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  version=datetime.utcnow().strftime(\"%Y%m%d%H%M\"),\n",
      "\u001b[32mUploading vqav2small (50.14 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50137461/50137461 [00:14<00:00, 3489514.10it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset created: vqav2small-llamafactory:202510291437\n",
      "URI: azureml://subscriptions/7a03e9b8-18d6-48e7-b186-0ec68da9e86f/resourcegroups/aml-rg/workspaces/aml-hu-east-west-us2/datastores/workspaceblobstore/paths/LocalUpload/6f1951706f548c8a1401400c9ea42a54ff5a9e1f0262a418343b51ff5b29aeba/vqav2small/\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from datetime import datetime\n",
    "\n",
    "# å°† vqav2small ç›®å½•æ³¨å†Œä¸º Data èµ„äº§\n",
    "vqav2_data_asset = Data(\n",
    "    name=\"vqav2small-llamafactory\",\n",
    "    version=datetime.utcnow().strftime(\"%Y%m%d%H%M\"),\n",
    "    path=output_base_dir,   # ç›®å½•ä¸­åŒ…å« train_images/val_images ä»¥åŠ json\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"VQA vqav2-small preprocessed for LLaMA-Factory (messages/images)\"\n",
    ")\n",
    "registered_vqav2 = ml_client.data.create_or_update(vqav2_data_asset)\n",
    "print(f\"Data asset created: {registered_vqav2.name}:{registered_vqav2.version}\")\n",
    "print(\"URI:\", registered_vqav2.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d63d4e",
   "metadata": {},
   "source": [
    "### æ³¨å†Œåå¯åœ¨azureçš„èµ„äº§é¡µé¢ä¸­æŸ¥çœ‹\n",
    "- ![æŸ¥çœ‹èµ„äº§](images/azure_ml_assets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7628bd",
   "metadata": {},
   "source": [
    "## 2.5 å†™å…¥ LLaMA-Factory è®­ç»ƒé…ç½® YAML(Qwen3-VL-4B LoRA)\n",
    "\n",
    "ç”Ÿæˆ `qwen3vl_lora_sft.yaml`,è®¾ç½® Qwen3-VL-4B-Instructã€LoRA è¶…å‚ã€batch/epochsã€æ—¥å¿—ä¸è¾“å‡ºç›®å½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8f1e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å†™å…¥é…ç½®: /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/config/qwen3vl_lora_sft.yaml\n",
      "é¢„æœŸè¾“å‡ºç›®å½•: /Users/chengbian/Documents/workspace/qwen_vl_lora/aml/workshop_qwen_vl/outputs/saves/qwen3vl-4b/lora/sft\n"
     ]
    }
   ],
   "source": [
    "yaml_path = (config_dir / \"qwen3vl_lora_sft.yaml\").as_posix()\n",
    "\n",
    "yaml_content = f\"\"\"\n",
    "### model\n",
    "model_name_or_path: Qwen/Qwen3-VL-4B-Instruct\n",
    "image_max_pixels: 262144\n",
    "video_max_pixels: 16384\n",
    "trust_remote_code: true\n",
    "\n",
    "### method\n",
    "stage: sft\n",
    "do_train: true\n",
    "finetuning_type: lora\n",
    "lora_rank: 16\n",
    "lora_target: all\n",
    "\n",
    "### dataset\n",
    "# æ³¨æ„ï¼šæ­¤å¤„ä½¿ç”¨è‡ªå®šä¹‰é¢„å¤„ç†åçš„ vqav2small_train.jsonï¼›\n",
    "# LLaMA-Factory è¯»å– JSON è·¯å¾„æ—¶è¯·ç”¨ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹å½“å‰å·¥ä½œç›®å½•\n",
    "# å¦‚æœéœ€è¦ï¼Œå¯æ”¹å†™ä¸ºä½ çš„è‡ªå®šä¹‰æ•°æ®é›†åç§°ä¸è·¯å¾„\n",
    "# è¿™é‡Œæ²¿ç”¨ workshop å‘½åï¼Œå…·ä½“è§£æé€»è¾‘ä»¥ llamafactory çš„æ•°æ®é€‚é…ä¸ºå‡†\n",
    "\n",
    "# å…¼å®¹ workshop çš„æœ€å°åŒ–é…ç½®ï¼›å¦‚éœ€ä¸¥æ ¼å¯¹é½ LF å®˜æ–¹æ•°æ®æ³¨å†Œï¼Œéœ€åœ¨ data/dataset_info.json ä¸­ç™»è®°\n",
    "# æ­¤å¤„åªä½œä¸ºæ¼”ç¤ºï¼ˆå®é™…è®­ç»ƒæ—¶å¯åœ¨å‘½ä»¤ä¸­é€šè¿‡ --dataset xxx æˆ–ä¼  data_path å‚æ•°ï¼‰\n",
    "dataset: vqav2small_train\n",
    "template: qwen3_vl\n",
    "cutoff_len: 2048\n",
    "max_samples: 1000\n",
    "overwrite_cache: true\n",
    "preprocessing_num_workers: 16\n",
    "dataloader_num_workers: 0\n",
    "\n",
    "### output\n",
    "output_dir: {outputs_dir.as_posix()}/saves/qwen3vl-4b/lora/sft\n",
    "logging_steps: 10\n",
    "save_steps: 200\n",
    "plot_loss: true\n",
    "overwrite_output_dir: true\n",
    "save_only_model: false\n",
    "report_to: none\n",
    "\n",
    "### train\n",
    "per_device_train_batch_size: 2\n",
    "gradient_accumulation_steps: 8\n",
    "learning_rate: 1.0e-4\n",
    "num_train_epochs: 1.0\n",
    "lr_scheduler_type: cosine\n",
    "warmup_ratio: 0.1\n",
    "bf16: true\n",
    "ddp_timeout: 180000000\n",
    "resume_from_checkpoint: null\n",
    "\"\"\"\n",
    "\n",
    "with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"å†™å…¥é…ç½®:\", yaml_path)\n",
    "print(\"é¢„æœŸè¾“å‡ºç›®å½•:\", (outputs_dir / \"saves/qwen3vl-4b/lora/sft\").as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199acc6f",
   "metadata": {},
   "source": [
    "## 2.6 æ³¨å†Œ/åˆ›å»º Azure ML ç¯å¢ƒ\n",
    "\n",
    "#### ğŸ¯ é•œåƒé€‰æ‹©å»ºè®®\n",
    "\n",
    "**å½“å‰é…ç½®ï¼ˆæ¨èï¼‰ï¼šHuggingFace NLP GPU ä¸“ç”¨é•œåƒ**\n",
    "```python\n",
    "image=\"mcr.microsoft.com/azureml/curated/acft-hf-nlp-gpu:latest\"\n",
    "```\n",
    "âœ… **ä¼˜ç‚¹ï¼š**\n",
    "- ä¸“é—¨ä¸º HuggingFace Transformers ä¼˜åŒ–\n",
    "- é¢„è£… CUDA 12.xï¼Œå®Œç¾æ”¯æŒæœ€æ–°çš„ bitsandbytes\n",
    "- é’ˆå¯¹ A100 GPU ä¼˜åŒ–\n",
    "- åŒ…å« NLP å’Œå¤šæ¨¡æ€ä»»åŠ¡çš„å¸¸ç”¨åº“\n",
    "\n",
    "**å…¶ä»–å¯ç”¨é€‰é¡¹ï¼š**\n",
    "\n",
    "| é•œåƒ | CUDA | é€‚ç”¨åœºæ™¯ | æ¨èåº¦ |\n",
    "|------|------|---------|--------|\n",
    "| `acft-hf-nlp-gpu:latest` | 12.x | HuggingFace + LoRA å¾®è°ƒ | â­â­â­â­â­ |\n",
    "| `pytorch-2.0-cuda11.7-cudnn8-ubuntu22.04:latest` | 11.7 | é€šç”¨ PyTorch è®­ç»ƒ | â­â­â­ |\n",
    "| `openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04:latest` | 11.8 | åˆ†å¸ƒå¼è®­ç»ƒ | â­â­â­ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aa44964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment registered: qwen3vl-lora-lf:2\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "aml_env = Environment(\n",
    "    name=\"qwen3vl-lora-lf\",\n",
    "    description=\"Curated PyTorch image; pip installs LLaMA-Factory during job\",\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acft-hf-nlp-gpu:latest\",\n",
    ")\n",
    "registered_env = ml_client.environments.create_or_update(aml_env)\n",
    "print(f\"Environment registered: {registered_env.name}:{registered_env.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd0bed",
   "metadata": {},
   "source": [
    "### å®Œæˆæ“ä½œåå¯ä»¥åœ¨ç¯å¢ƒé¡µé¢è¿›è¡ŒæŸ¥çœ‹\n",
    "\n",
    "- ![æŸ¥çœ‹ç¯å¢ƒ](images/azure_ml_environment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4305a4",
   "metadata": {},
   "source": [
    "## 2.7 åˆ›å»ºå¹¶æäº¤ LLaMA-Factory è®­ç»ƒå‘½ä»¤ä½œä¸š(AML)\n",
    "\n",
    "### è®¡ç®—èµ„æºå‡†å¤‡\n",
    "1. æ¨èä½¿ç”¨å¸¦ A100 80GB çš„ GPUï¼ˆå¦‚ `Standard_NC24ads_A100_v4`ï¼‰ã€‚\n",
    "2. è‹¥å°šæœªåˆ›å»ºè®¡ç®—é›†ç¾¤ï¼Œå¯åœ¨ Azure ML Studio â†’ è®¡ç®— â†’ è®¡ç®—é›†ç¾¤ åˆ›å»ºï¼Œæˆ–ä½¿ç”¨ Azure CLIï¼š\n",
    "   ```bash\n",
    "   az ml compute create --name gpu-a100-cluster --type amlcompute \\\n",
    "       --resource-group <RG> --workspace-name <WS> \\\n",
    "       --min-instances 0 --max-instances 2 --size Standard_NC24ads_A100_v4\n",
    "   ```\n",
    "3. è®­ç»ƒå‰ç¡®è®¤é›†ç¾¤å¤„äºâ€œç©ºé—²â€æˆ–â€œå·²åˆ†é…â€çŠ¶æ€ï¼Œç¡®ä¿é…é¢è¶³å¤Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3637e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç°æœ‰è®¡ç®—èµ„æº:\n",
      "  - A100-swedCentral (ç±»å‹: virtualmachine, å¤§å°: N/A, çŠ¶æ€: Succeeded)\n",
      "  - A100-centre-us (ç±»å‹: virtualmachine, å¤§å°: N/A, çŠ¶æ€: Succeeded)\n",
      "  - multi-model-batch-vm (ç±»å‹: computeinstance, å¤§å°: Standard_D96ads_v5, çŠ¶æ€: Succeeded)\n",
      "  - o1-performance-test-vm (ç±»å‹: computeinstance, å¤§å°: Standard_E4ds_v4, çŠ¶æ€: Succeeded)\n",
      "  - slm-fine-tune-lab (ç±»å‹: computeinstance, å¤§å°: Standard_E4ds_v4, çŠ¶æ€: Succeeded)\n",
      "  - gpu-cluster-a100 (ç±»å‹: amlcompute, å¤§å°: Standard_NC24ads_A100_v4, çŠ¶æ€: Succeeded)\n",
      "  - agent-demo-ws (ç±»å‹: computeinstance, å¤§å°: Standard_D32d_v4, çŠ¶æ€: Succeeded)\n",
      "  - notebook-llm-solu-vm (ç±»å‹: computeinstance, å¤§å°: Standard_D48a_v4, çŠ¶æ€: Succeeded)\n",
      "  - gpu-phi4-predict-out (ç±»å‹: computeinstance, å¤§å°: Standard_NC8as_T4_v3, çŠ¶æ€: Succeeded)\n",
      "  - Standard-NV12s-v3-m60 (ç±»å‹: computeinstance, å¤§å°: Standard_NV12s_v3, çŠ¶æ€: Succeeded)\n",
      "  - multi-gpus-trainer (ç±»å‹: computeinstance, å¤§å°: Standard_NC64as_T4_v3, çŠ¶æ€: Succeeded)\n",
      "  - a100-west-1 (ç±»å‹: amlcompute, å¤§å°: Standard_NC24ads_A100_v4, çŠ¶æ€: Succeeded)\n",
      "  - qwen-fine-tune-A100 (ç±»å‹: computeinstance, å¤§å°: Standard_NC48ads_A100_v4, çŠ¶æ€: Succeeded)\n",
      "  - qwen-fine-tune-H100 (ç±»å‹: amlcompute, å¤§å°: Standard_NC80adis_H100_v5, çŠ¶æ€: Succeeded)\n",
      "  - qwen-25-vl-finetune (ç±»å‹: computeinstance, å¤§å°: Standard_NC80adis_H100_v5, çŠ¶æ€: Succeeded)\n",
      "\n",
      "è®¡ç®—é›†ç¾¤ 'qwen-fine-tune-H100' å·²å­˜åœ¨ï¼ŒçŠ¶æ€: Succeeded\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥ç°æœ‰è®¡ç®—èµ„æºå¹¶åœ¨éœ€è¦æ—¶åˆ›å»º GPU é›†ç¾¤\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# åˆ—å‡ºæ‰€æœ‰ç°æœ‰çš„è®¡ç®—èµ„æº\n",
    "print(\"ç°æœ‰è®¡ç®—èµ„æº:\")\n",
    "for compute in ml_client.compute.list():\n",
    "    print(f\"  - {compute.name} (ç±»å‹: {compute.type}, å¤§å°: {getattr(compute, 'size', 'N/A')}, çŠ¶æ€: {compute.provisioning_state})\")\n",
    "\n",
    "# å®šä¹‰è®¡ç®—é›†ç¾¤åç§°\n",
    "COMPUTE_NAME = \"qwen-fine-tune-H100\"\n",
    "\n",
    "# æ£€æŸ¥è®¡ç®—é›†ç¾¤æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(COMPUTE_NAME)\n",
    "    print(f\"\\nè®¡ç®—é›†ç¾¤ '{COMPUTE_NAME}' å·²å­˜åœ¨ï¼ŒçŠ¶æ€: {compute_target.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nè®¡ç®—é›†ç¾¤ '{COMPUTE_NAME}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...\")\n",
    "    \n",
    "    # åˆ›å»ºè®¡ç®—é›†ç¾¤é…ç½®\n",
    "    # æ³¨æ„ï¼šStandard_NC24ads_A100_v4 åœ¨æŸäº›åŒºåŸŸå¯èƒ½ä¸å¯ç”¨\n",
    "    # å¯æ›¿æ¢ä¸ºå…¶ä»– GPU SKUï¼Œå¦‚ Standard_NC6s_v3, Standard_NC12s_v3 ç­‰\n",
    "    compute_config = AmlCompute(\n",
    "        name=COMPUTE_NAME,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_NC80adis_H100_v5\",  # A100 80GB GPU\n",
    "        min_instances=0,\n",
    "        max_instances=1,\n",
    "        idle_time_before_scale_down=300,  # 5åˆ†é’Ÿåè‡ªåŠ¨ç¼©å‡\n",
    "        tier=\"dedicated\",\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        compute_target = ml_client.compute.begin_create_or_update(compute_config).result()\n",
    "        print(f\"è®¡ç®—é›†ç¾¤ '{COMPUTE_NAME}' åˆ›å»ºæˆåŠŸï¼\")\n",
    "    except Exception as create_error:\n",
    "        print(f\"åˆ›å»ºå¤±è´¥: {create_error}\")\n",
    "        print(\"\\nå¯èƒ½çš„åŸå› :\")\n",
    "        print(\"1. æ‰€é€‰ GPU SKU åœ¨å½“å‰åŒºåŸŸä¸å¯ç”¨\")\n",
    "        print(\"2. GPU é…é¢ä¸è¶³\")\n",
    "        print(\"\\nå»ºè®®:\")\n",
    "        print(\"- åœ¨ Azure Portal ä¸­æ£€æŸ¥å¯ç”¨çš„ VM SKU\")\n",
    "        print(\"- è¯·æ±‚å¢åŠ  GPU é…é¢\")\n",
    "        print(\"- æˆ–ä½¿ç”¨ç°æœ‰çš„è®¡ç®—èµ„æºï¼ˆå¦‚æœä¸Šé¢åˆ—å‡ºäº†å¯ç”¨çš„è®¡ç®—ï¼‰\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef4614",
   "metadata": {},
   "source": [
    "### å®Œæˆè®¡ç®—èµ„æºå‡†å¤‡åï¼Œ æäº¤è®­ç»ƒå‘½ä»¤\n",
    "å‘½ä»¤ä¼šåœ¨è®¡ç®—èŠ‚ç‚¹ä¸Š:\n",
    "1) å…‹éš† LLaMA-Factory å¹¶å®‰è£…;2) è®¾ç½® HF é•œåƒä¸åŠ é€Ÿ;3) è¯»å–æŒ‚è½½çš„æ•°æ®ç›®å½•;4) è°ƒç”¨ `llamafactory-cli train` ä½¿ç”¨ä¸Šæ–‡ YAML é…ç½®ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fe2bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'qwen3vl-lora-lf' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'qwen3vl-lora-lf' will not be used for anonymous registration\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job submitted: cool_head_rrkrh8znqf\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import Input, Output, command\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# è®¡ç®—ä¸å®éªŒé…ç½®ï¼ˆè¯·æ ¹æ®ä½ çš„å·¥ä½œåŒºå®é™…å€¼ä¿®æ”¹ï¼‰\n",
    "EXPERIMENT_NAME = \"qwen3vl-lora-lf\"\n",
    "\n",
    "# ä½¿ç”¨ä¸Šé¢æ³¨å†Œçš„ Data èµ„äº§ä½œä¸ºè¾“å…¥\n",
    "data_input = Input(type=AssetTypes.URI_FOLDER, path=registered_vqav2.id)\n",
    "\n",
    "# è®­ç»ƒå‘½ä»¤ï¼šåœ¨èŠ‚ç‚¹ä¸Šå®‰è£… LLaMA-Factory å¹¶è¿è¡Œè®­ç»ƒ\n",
    "# æ³¨æ„ï¼š${{inputs.data}} ä¸º Azure ML åœ¨è¿è¡Œæ—¶æ³¨å…¥çš„æŒ‚è½½è·¯å¾„\n",
    "train_cmd = \" && \".join([\n",
    "    \"set -e\",\n",
    "    \"echo \\\"Python:\\\" $(python --version)\",\n",
    "    \"echo \\\"Pip:\\\" $(pip --version)\",\n",
    "    \"git clone https://github.com/hiyouga/LLaMA-Factory.git\",\n",
    "    \"cd LLaMA-Factory\",\n",
    "    \"export HF_HUB_ENABLE_HF_TRANSFER=1\",\n",
    "    \"if [ \\\"$AZURE_CLOUD_NAME\\\" = \\\"AzureChinaCloud\\\" ]; then export HF_ENDPOINT=https://hf-mirror.com; fi\",\n",
    "    \"pip install -e \\\".[torch,metrics]\\\" --no-build-isolation\",\n",
    "    f\"llamafactory-cli train {yaml_path}\",\n",
    "])\n",
    "\n",
    "job = command(\n",
    "    code=str(workspace_dir),\n",
    "    command=train_cmd,\n",
    "    inputs={\"data\": data_input},\n",
    "    environment=registered_env,\n",
    "    compute=COMPUTE_NAME,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    display_name=\"qwen3vl-lora-train-lf\",\n",
    "    outputs={\n",
    "        \"trained\": Output(type=AssetTypes.URI_FOLDER)  # å°†é»˜è®¤å†™å…¥ä½œä¸šè¾“å‡ºç›®å½•\n",
    "    },\n",
    "    description=\"Qwen3-VL-4B LoRA training via LLaMA-Factory\"\n",
    ")\n",
    "\n",
    "# ä»¥æŒ‚è½½æ–¹å¼è®¿é—®æ•°æ®ï¼ˆæå‡ I/O é€Ÿåº¦ï¼‰\n",
    "job.inputs[\"data\"].mode = \"mount\"\n",
    "submitted_job = ml_client.jobs.create_or_update(job)\n",
    "print(\"Job submitted:\", submitted_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4fa95c",
   "metadata": {},
   "source": [
    "## 2.8 ç›‘æ§è®­ç»ƒæ—¥å¿—(AML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.stream(submitted_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401c00c",
   "metadata": {},
   "source": [
    "## 2.9 ä¸‹è½½è®­ç»ƒè¾“å‡ºå¹¶å±•ç¤ºæŸå¤±æ›²çº¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, tempfile\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# ä¸‹è½½ä½œä¸šäº§ç‰©åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•\n",
    "local_download = pathlib.Path(tempfile.mkdtemp(prefix=\"aml-train-\"))\n",
    "ml_client.jobs.download(submitted_job.name, download_path=local_download.as_posix())\n",
    "print(\"Downloaded to:\", local_download)\n",
    "\n",
    "# æœç´¢ training_loss.png\n",
    "loss_png = None\n",
    "for p in local_download.rglob(\"training_loss.png\"):\n",
    "    loss_png = p\n",
    "    break\n",
    "\n",
    "if loss_png and loss_png.exists():\n",
    "    print(\"Found:\", loss_png)\n",
    "    display(Image.open(loss_png).convert(\"RGB\"))\n",
    "else:\n",
    "    print(\"æœªæ‰¾åˆ° training_loss.pngã€‚è¯·æ£€æŸ¥ä½œä¸šè¾“å‡ºç›®å½•ç»“æ„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738b5aa",
   "metadata": {},
   "source": [
    "## 2.10 åˆå¹¶ LoRA é€‚é…å™¨ä¸ºå®Œæ•´æ¨¡å‹(AML å¯¼å‡ºä½œä¸š)\n",
    "\n",
    "ä½¿ç”¨ç¬¬äºŒä¸ªå‘½ä»¤ä½œä¸šåœ¨è®¡ç®—èŠ‚ç‚¹ä¸Šè¿è¡Œ `llamafactory-cli export`,å°†å‰ä¸€ä½œä¸šçš„ LoRA é€‚é…å™¨ä¸åŸºç¡€æ¨¡å‹åˆå¹¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "\n",
    "# å°†ä¸Šä¸€ä¸ªä½œä¸šçš„é»˜è®¤ outputs ä½œä¸ºè¾“å…¥ä¼ å…¥\n",
    "prev_outputs_uri = f\"azureml://jobs/{submitted_job.name}/outputs\"\n",
    "prev_input = Input(type=AssetTypes.URI_FOLDER, path=prev_outputs_uri)\n",
    "\n",
    "merge_cmd = \" && \".join([\n",
    "    \"set -e\",\n",
    "    \"git clone https://github.com/hiyouga/LLaMA-Factory.git\",\n",
    "    \"cd LLaMA-Factory\",\n",
    "    \"pip install -e \\\".[torch,metrics]\\\" --no-build-isolation\",\n",
    "    # é€‰æ‹©æœ€è¿‘çš„ checkpoint ç›®å½•\n",
    "    \"ADAPTER=$(ls -d ${inputs.prev}/saves/qwen3vl-4b/lora/sft/checkpoint-* | sort | tail -n 1)\",\n",
    "    \"echo Using adapter: $ADAPTER\",\n",
    "    # ç”Ÿæˆåˆå¹¶é…ç½®æ–‡ä»¶\n",
    "    \"cat > merge_lora.yaml <<'EOF'\\n\"\n",
    "    \"### model\\n\"\n",
    "    \"model_name_or_path: Qwen/Qwen3-VL-4B-Instruct\\n\"\n",
    "    \"adapter_name_or_path: $ADAPTER\\n\"\n",
    "    \"template: qwen3_vl\\n\"\n",
    "    \"trust_remote_code: true\\n\\n\"\n",
    "    \"### export\\n\"\n",
    "    \"export_dir: ./outputs/merged\\n\"\n",
    "    \"export_size: 5\\n\"\n",
    "    \"export_device: cpu\\n\"\n",
    "    \"export_legacy_format: false\\n\"\n",
    "    \"EOF\",\n",
    "    # æ‰§è¡Œå¯¼å‡º\n",
    "    \"llamafactory-cli export merge_lora.yaml\",\n",
    "])\n",
    "\n",
    "merge_job = command(\n",
    "    code=str(workspace_dir),\n",
    "    command=merge_cmd,\n",
    "    inputs={\"prev\": prev_input},\n",
    "    environment=registered_env,\n",
    "    compute=COMPUTE_NAME,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    display_name=\"qwen3vl-merge-lora\",\n",
    "    outputs={\"merged\": Output(type=AssetTypes.URI_FOLDER)},\n",
    "    description=\"Merge LoRA adapter into full model\"\n",
    ")\n",
    "\n",
    "merge_job.inputs[\"prev\"].mode = \"download\"  # è¯»å–ä¸Šæ¬¡ä½œä¸šäº§ç‰©\n",
    "submitted_merge = ml_client.jobs.create_or_update(merge_job)\n",
    "print(\"Merge job submitted:\", submitted_merge.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc694df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›‘æ§åˆå¹¶ä½œä¸š\n",
    "ml_client.jobs.stream(submitted_merge.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a9289b",
   "metadata": {},
   "source": [
    "## 2.11 æ³¨å†Œ LoRA é€‚é…å™¨/åˆå¹¶æ¨¡å‹ä¸º Azure ML æ¨¡å‹èµ„äº§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabcb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "BASE_MODEL = \"Qwen/Qwen3-VL-4B-Instruct\"\n",
    "\n",
    "# é€‚é…å™¨æ¨¡å‹ï¼ˆæ³¨å†Œè®­ç»ƒä½œä¸šçš„ outputs ç›®å½•ï¼‰\n",
    "adapter_uri = f\"azureml://jobs/{submitted_job.name}/outputs\"\n",
    "adapter_model = Model(\n",
    "    name=\"qwen3vl-lora-adapter-lf\",\n",
    "    path=adapter_uri,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"LoRA adapter trained via LLaMA-Factory on AML\",\n",
    "    tags={\"base_model\": BASE_MODEL, \"task\": \"sft\", \"tool\": \"llamafactory\"}\n",
    ")\n",
    "reg_adapter = ml_client.models.create_or_update(adapter_model)\n",
    "print(\"Adapter model:\", f\"{reg_adapter.name}:{reg_adapter.version}\")\n",
    "\n",
    "# åˆå¹¶åå®Œæ•´æ¨¡å‹ï¼ˆæ³¨å†Œå¯¼å‡ºä½œä¸šçš„ merged è¾“å‡ºï¼‰\n",
    "merged_uri = f\"azureml://jobs/{submitted_merge.name}/outputs/merged\"\n",
    "full_model = Model(\n",
    "    name=\"qwen3vl-merged-lf\",\n",
    "    path=merged_uri,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"Full model merged from base + LoRA via LLaMA-Factory export\",\n",
    "    tags={\"base_model\": BASE_MODEL, \"merged\": \"true\", \"tool\": \"llamafactory\"}\n",
    ")\n",
    "reg_full = ml_client.models.create_or_update(full_model)\n",
    "print(\"Merged model:\", f\"{reg_full.name}:{reg_full.version}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
